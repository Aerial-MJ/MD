# "ReActing Agents for Finance: LLM-based Multi-Agent Reasoning and Decision-Making in Investment Environments"

è‡ªæˆ‘çº æ­£æœºåˆ¶ï¼Œå¦‚åŸºäºå¼ºåŒ–å­¦ä¹ çš„è‡ªæˆ‘çº æ­£ï¼Œä»¥åŠè§„åˆ™åŸºç¡€çš„å¥–åŠ±ç»“æ„ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éµå¾ªç‰¹å®šçš„å®‰å…¨å’Œå‡†ç¡®æ€§æŒ‡å—



å¤ªå¥½äº†ï¼ä½ ç°åœ¨è¿™ä¸ªå¤šæ™ºèƒ½ä½“ç³»ç»Ÿå·²ç»å¯ä»¥ï¼š

âœ… æ”¯æŒæ¯ä¸ª Agent è§’è‰²ç‹¬ç«‹ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œè‡ªç„¶è¯­è¨€åˆ†æ
âœ… è‡ªåŠ¨æ±‡æ€»å„ Agent çš„å»ºè®®ï¼Œç”± CIO ç»Ÿä¸€è¾“å‡ºæœ€ç»ˆæ“ä½œ
âœ… ç»“æ„æ¸…æ™°ï¼Œåç»­å¯æ‰©å±•æ€§å¼ºï¼ˆæ”¯æŒæ¥å…¥å¼ºåŒ–å­¦ä¹ ã€è‡ªæ¼”åŒ–ã€è®°å¿†æœºåˆ¶ç­‰ï¼‰

------

### ğŸ”§ ä¸‹ä¸€æ­¥æ¨èä¼˜åŒ–æ–¹å‘ï¼ˆä½ å¯ä»¥è‡ªç”±é€‰æ‹©ï¼‰ï¼š

#### âœ… æ•°æ®é©±åŠ¨ä¼˜åŒ–ï¼ˆæ¨èä½œä¸ºä¸‹ä¸€é˜¶æ®µé‡ç‚¹ï¼‰ï¼š

-  å¯¹æ¥ CSVï¼ˆä½ çš„ `financial_final.csv`ï¼‰ï¼Œæ‰¹é‡æ‰§è¡Œå¤šæ—¥åˆ†æ
-  åŠ å…¥æ•°æ®é¢„å¤„ç†/ç¼ºå¤±å€¼å¤„ç†é€»è¾‘
-  è¾“å‡ºæ¯ä¸ª Agent æ¯æ—¥çš„ actionã€reason åˆ°æ—¥å¿—æˆ– DataFrame

#### ğŸ§  Agent èƒ½åŠ›å‡çº§æ–¹å‘ï¼š

-  ç”¨æç¤ºè¯+few-shot æ–¹å¼å¾®è°ƒ promptï¼Œä½¿æ¯ç±» Agent æ›´æœ‰é£æ ¼
-  ç»™ CIO Agent åŠ ä¸Š**ä¿¡ä»»åº¦åŠ¨æ€è°ƒæ•´**ï¼Œä¸åŒ Agent çš„å»ºè®®æƒé‡å¯å˜
-  åŠ å…¥ memory/history æ¨¡å—ï¼ŒAgent å¯ä»¥è®°ä½è¿‡å»å‡ å¤©èµ°åŠ¿

#### ğŸ¤– ç³»ç»Ÿæ¶æ„å‡çº§æ–¹å‘ï¼š

-  ç”¨ ReAct æ¶æ„è®¾è®¡æ¯ä¸ª Agent çš„è¡Œä¸ºæµç¨‹ï¼ˆæ„ŸçŸ¥ â†’ è®¡åˆ’ â†’ æ‰§è¡Œï¼‰
-  æ„å»º AgentManager æˆ– AgentHub æ¨¡å—æ¥ç®¡ç† Agent çš„ç”Ÿå‘½å‘¨æœŸï¼ˆåŠ¨æ€åˆ›å»º/é”€æ¯ï¼‰
-  æ•´åˆ PPO å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æ•´ä¸ªå†³ç­–ç³»ç»Ÿï¼ˆåç»­é˜¶æ®µï¼‰

------

ä½ ç°åœ¨æƒ³ï¼š

A. åšä¸€ä¸ª**æ‰¹é‡æ•°æ®è¿è¡Œè„šæœ¬**ï¼Œè®©è¿™ä¸ªç³»ç»Ÿè·‘è¿‡å»å‡ å¤©çš„é¢„æµ‹ï¼Ÿ
B. æˆ–è€…åŠ ç‚¹é£æ ¼/å†…å®¹ prompt å¾®è°ƒæ¯ä¸ª Agent è§’è‰²ï¼Ÿ
C. è¿˜æ˜¯ä½ æœ‰åˆ«çš„ä¼˜å…ˆæƒ³æ³•ï¼Œæˆ‘è·Ÿç€ä½ èµ° ğŸ˜

# å¥½çš„ï¼Œè¿™ä¸ªMetaAgentå’ŒMeta-Controlleræ˜¯ä¸€ä¸ªä¸œè¥¿å—ï¼Ÿ

å¾ˆå¥½ï¼Œè¿™ä¸ªé—®é¢˜éå¸¸å…³é”®ã€‚æ ¹æ®ä½ æ–‡æ¡£çš„æè¿°ï¼Œâ€œMetaAgentâ€å’Œâ€œMeta-Controllerâ€**ä¸æ˜¯åŒä¸€ä¸ªä¸œè¥¿**ï¼Œè™½ç„¶å®ƒä»¬éƒ½å‘æŒ¥äº†â€œé«˜å±‚æ§åˆ¶â€ä½œç”¨ï¼Œä½†èŒè´£ä¸åŒï¼Œå…·ä½“å¦‚ä¸‹ï¼š

------

### âœ… **MetaAgent**ï¼ˆå…ƒæ™ºèƒ½ä½“ï¼‰

- **ä½œç”¨**ï¼šèšåˆä¸èåˆå„åˆ†ææ™ºèƒ½ä½“ï¼ˆå¦‚æŠ€æœ¯ã€åŸºæœ¬é¢ã€æƒ…ç»ªåˆ†æå¸ˆï¼‰çš„å»ºè®®ï¼Œå½¢æˆæœ€ç»ˆçš„äº¤æ˜“å†³ç­–ã€‚
- **å…³é”®è¯**ï¼šå»ºè®®èåˆï¼ˆpolicy fusionï¼‰ã€æƒé‡è°ƒæ•´ã€æœ€ç»ˆå†³ç­–ã€‚
- **æœºåˆ¶**ï¼šå—å¼ºåŒ–å­¦ä¹ ç­–ç•¥æŒ‡å¯¼ï¼Œé€‰æ‹©æ˜¯å¦å¹³å‡ã€æŠ•ç¥¨ã€ç­›é€‰ã€å¿½ç•¥æŸäº› Agent çš„å»ºè®®ã€‚

å¯ä»¥ç†è§£ä¸ºï¼šå®ƒå°±åƒæŠ•èµ„å…¬å¸çš„ **é¦–å¸­æŠ•èµ„å®˜ï¼ˆCIOï¼‰**ï¼Œæ¥æ”¶æ‰€æœ‰åˆ†æå¸ˆçš„å»ºè®®ï¼Œå†³å®šæ˜¯å¦é‡‡çº³å¹¶åšå‡ºæœ€ç»ˆäº¤æ˜“å†³ç­–ã€‚

------

### âœ… **Meta-Controller**ï¼ˆå…ƒæ§åˆ¶å™¨ï¼‰

- **ä½œç”¨**ï¼šç®¡ç†æ•´ä¸ªå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„ç»“æ„æ¼”åŒ–ï¼Œä¾‹å¦‚ï¼š
  - åˆ›å»ºæ–°çš„ Agentï¼ˆä¾‹å¦‚åº”å¯¹çªå‘å¸‚åœºæƒ…ç»ªï¼‰
  - åˆå¹¶å†—ä½™ Agent
  - å…³é—­è¡¨ç°ä¸ä½³çš„ Agent
- **å…³é”®è¯**ï¼šç»“æ„è¿›åŒ–ã€è‡ªæˆ‘æ¼”åŒ–ã€ç³»ç»Ÿç®¡ç†ã€‚
- **æœºåˆ¶**ï¼šç»“åˆ RLã€å¯å‘å¼è§„åˆ™å’Œåæ€å‹ reasoningï¼ˆReAct + Self-Reflectionï¼‰ã€‚

å¯ä»¥ç†è§£ä¸ºï¼šå®ƒåƒå…¬å¸çš„ **äººåŠ›èµ„æºä¸ç»„ç»‡æ¶æ„è´Ÿè´£äºº**ï¼Œå†³å®šè°åŠ å…¥ã€è°ç¦»å¼€ï¼Œä»¥åŠå›¢é˜Ÿè¯¥å¦‚ä½•å˜å½¢é€‚åº”å¸‚åœºã€‚

------

### ğŸ“Œ æ€»ç»“åŒºåˆ«ï¼š

| ç‰¹æ€§     | MetaAgentï¼ˆCIOï¼‰        | Meta-Controllerï¼ˆç»“æ„ç®¡ç†è€…ï¼‰   |
| -------- | ----------------------- | ------------------------------- |
| ä¸»è¦ä»»åŠ¡ | æ±‡æ€»ä¸å†³ç­– Agent çš„å»ºè®® | ç®¡ç† Agent è§’è‰²çš„å­˜åœ¨ä¸ç»“æ„æ¼”åŒ– |
| è¾“å…¥     | å„ Agent çš„ output      | å¸‚åœºç¯å¢ƒ + Agent è¡¨ç°æ•°æ®       |
| è¾“å‡º     | æœ€ç»ˆäº¤æ˜“æŒ‡ä»¤            | Agent å¢å‡/èåˆ/æ¿€æ´»/æš‚åœæŒ‡ä»¤   |
| ä½¿ç”¨æŠ€æœ¯ | å¼ºåŒ–å­¦ä¹ ç­–ç•¥èåˆ        | å¼ºåŒ–å­¦ä¹  + å¯å‘å¼ + è‡ªæˆ‘åæ€    |
| ç±»æ¯”     | é¦–å¸­æŠ•èµ„å®˜ï¼ˆCIOï¼‰       | äººæ‰ç®¡ç†ä¸ç»„ç»‡æ¼”è¿›éƒ¨é—¨è´Ÿè´£äºº    |

------

å¦‚æœä½ æƒ³è®©è¿™ä¸¤ä¸ªåˆå¹¶ä¸ºä¸€ä¸ªç»Ÿä¸€çš„æ¨¡å—ï¼ˆæ¯”å¦‚ MetaAgent åŒæ—¶è´Ÿè´£å»ºè®®èåˆ + ç³»ç»Ÿæ¼”åŒ–ï¼‰ï¼Œä¹Ÿå¯ä»¥ï¼Œä½†éœ€è¦æ˜ç¡®å®šä¹‰å…¶å­æ¨¡å—èŒè´£ï¼Œé¿å…è€¦åˆè¿‡é‡ã€‚å¦‚æœæ–‡ä¸­æƒ³è¦åˆå¹¶ï¼Œå¯ä»¥è€ƒè™‘ç»Ÿä¸€å«åš `MetaAgent`ï¼Œå†…éƒ¨å†åˆ†ä¸ºï¼š

- `DecisionModule`
- `EvolutionModule`

ä½ æ›´å€¾å‘ä¿ç•™è¿™ä¸¤ä¸ªåå­—ï¼Œè¿˜æ˜¯åˆå¹¶ç®€åŒ–ï¼Ÿæˆ‘å¯ä»¥å¸®ä½ ç»Ÿä¸€æ–‡æ¡£æœ¯è¯­ã€‚

# ä¸¤ä¸ªéƒ½è¦å’Œrlè”åˆå—ï¼Ÿ

ä½ çš„é—®é¢˜å¾ˆå…³é”®ï¼Œå›ç­”æ˜¯ï¼š

**ä¸ä¸€å®šä¸¤ä¸ªéƒ½å¿…é¡»å’Œ RL è”åˆï¼Œä½†æˆ‘ä»¬å»ºè®®ä»¥ä¸åŒæ–¹å¼ç»“åˆ RLï¼š**

---

### âœ… å½“å‰æ¶æ„ä¸­ä¸¤ä¸ªâ€œæ§åˆ¶å±‚â€çš„è§’è‰²åˆ†åˆ«æ˜¯ï¼š

1. **MetaAgentï¼ˆç”¨äºç­–ç•¥èåˆï¼‰**
   * ä»»åŠ¡ï¼šå†³å®šå¦‚ä½•èåˆå¤šä¸ª Agent çš„å»ºè®®ï¼ˆæ¯”å¦‚åŠ æƒå¹³å‡ã€é€‰æ‹©æœ€å¯ä¿¡çš„ä¸€ä¸ªã€æŠ•ç¥¨ç­‰ï¼‰
   * ç›®æ ‡ï¼š**è¾“å‡ºæœ€ç»ˆäº¤æ˜“å†³ç­–**
   * **æ¨èæ–¹å¼ï¼šç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ¥æŒ‡å¯¼ç­–ç•¥èåˆ**
   
     * å› ä¸ºè¿™æ˜¯ä¸€ä¸ªæ˜ç¡®çš„å†³ç­–ä¼˜åŒ–é—®é¢˜ï¼Œå¯ä»¥å®šä¹‰ rewardï¼ˆå¦‚ç´¯ç§¯æ”¶ç›Šã€Sharpe ratioï¼‰
     * å¯è§†ä¸º policy fusion çš„ RL ç­–ç•¥å­¦ä¹ é—®é¢˜
   
2. **Meta-Controllerï¼ˆç”¨äºç»“æ„æ¼”åŒ–ï¼‰**

   * ä»»åŠ¡ï¼šå†³å®šæ˜¯å¦æ·»åŠ /åˆ é™¤/åˆå¹¶/æ¿€æ´»æŸäº› Agent
   * ç›®æ ‡ï¼š**è°ƒæ•´ç³»ç»Ÿç»“æ„é€‚åº”å¸‚åœºå˜åŒ–**
   * **æ¨èæ–¹å¼ï¼šRL + Heuristics + è‡ªåå¼ reasoningï¼ˆå¦‚ ReAct + Self-Reflectionï¼‰è”åˆä½¿ç”¨**

     * çº¯ç”¨ RL ä¼šé¢ä¸´ç¨€ç–åé¦ˆå’Œé«˜å»¶è¿Ÿé—®é¢˜ï¼ˆå› ä¸ºç»“æ„å˜åŠ¨åçš„æ•ˆæœè¦ç­‰ä¸€æ®µæ—¶é—´æ‰èƒ½ä½“ç°ï¼‰
     * å¯ä»¥åœ¨å†³ç­–ä¸­åµŒå…¥å¯å‘å¼è§„åˆ™ï¼ˆå¦‚â€œæŠ€æœ¯åˆ†æé•¿æœŸä¸ç¨³å®šåˆ™é™æƒâ€ï¼‰ä¸ LLM åæ€èƒ½åŠ›ï¼ˆè®°å½•è¿‡å»çš„ç»“æ„è°ƒæ•´åŠç»“æœï¼‰

---

### æ€»ç»“å»ºè®®ï¼š

| æ§åˆ¶æ¨¡å—                 | æ˜¯å¦å¿…é¡»ç”¨ RL        | æ¨èå®ç°æ–¹å¼                                        |
| ------------------------ | -------------------- | --------------------------------------------------- |
| MetaAgent ç­–ç•¥èåˆ       | âœ… å¼ºçƒˆå»ºè®®           | ç”¨ RL ç›´æ¥ä¼˜åŒ–ç­–ç•¥èåˆæ•ˆæœ                          |
| Meta-Controller ç»“æ„æ¼”åŒ– | âœ… å»ºè®®ä¸å…¶ä»–ç»“åˆä½¿ç”¨ | RLï¼ˆç»“æ„è°ƒæ•´ç­–ç•¥ï¼‰+ Heuristic + LLM Self-Reflection |

ä½ ä¹Ÿå¯ä»¥åœ¨å®éªŒè®¾è®¡ä¸Šåšå¯¹æ¯”ï¼Œæ¯”å¦‚ï¼š

* MetaAgent æœ‰æ—  RL å­¦ä¹ å·®å¼‚ï¼ˆé™æ€èåˆ vs åŠ¨æ€èåˆï¼‰
* Meta-Controller çº¯å¯å‘å¼ vs RL é©±åŠ¨ vs è”åˆå¼æ§åˆ¶æ€§èƒ½å·®å¼‚

å¦‚æœä½ æƒ³ï¼Œæˆ‘å¯ä»¥å¸®ä½ ç”»ä¸ªç³»ç»Ÿå›¾æˆ–è€…æŠŠè¿™ä¸ªæ€è·¯èè¿›ä½ çš„è®ºæ–‡æ­£æ–‡éƒ¨åˆ†ã€‚éœ€è¦çš„è¯è¯´ä¸€å£°å°±è¡Œã€‚

# ä¹Ÿå°±æ˜¯è¯´metacontrolleræ˜¯æµç¨‹çš„å‰é¢éƒ¨åˆ†ï¼Œç„¶åmetaAgentæ˜¯åé¢éƒ¨åˆ†ï¼Ÿ

å®Œå…¨æ­£ç¡®ï¼ä½ å¯ä»¥è¿™æ ·ç†è§£è¿™ä¸¤ä¸ªæ¨¡å—åœ¨æ•´ä¸ªç³»ç»Ÿæµç¨‹ä¸­çš„ä½ç½®å’ŒèŒè´£ï¼š

------

### ğŸ§  **Meta-Controllerï¼šæµç¨‹å‰ç«¯ï¼Œç»“æ„ç®¡ç†è€…**

- **æ—¶æœº**ï¼š**åœ¨æ¯ä¸€è½®å†³ç­–å¼€å§‹å‰**ï¼Œæ ¹æ®å¸‚åœºçŠ¶æ€ + å†å²æ•ˆæœå†³å®šå“ªäº› Agent åº”è¯¥è¢«å¯ç”¨/æš‚åœ/æ–°å¢/åˆå¹¶
- **ç›®æ ‡**ï¼š**é…ç½®æœ€é€‚åˆå½“å‰å¸‚åœºçš„ Agent ç»„åˆä¸æ‹“æ‰‘ç»“æ„**
- **å†³ç­–ç±»å‹**ï¼šç»“æ„çº§ã€é•¿æœŸæ€§
- **æ§åˆ¶åŠ¨ä½œ**ï¼šadd / remove / merge / freeze agentsï¼Œè°ƒæ•´ Agent æƒé‡ä¸Šé™ç­‰

ğŸ‘‰ å®ƒæ›´åƒæ˜¯ä¸€ä¸ªâ€œæŠ•èµ„æ€»ç›‘â€ï¼Œå†³å®šç»„å»ºä»€ä¹ˆæ ·çš„å›¢é˜Ÿæ¥æ‰“ä»Šå¤©çš„ä»—ã€‚

------

### ğŸ§  **MetaAgentï¼ˆæˆ– Central Fusion Moduleï¼‰ï¼šæµç¨‹åç«¯ï¼Œç­–ç•¥èåˆè€…**

- **æ—¶æœº**ï¼š**æ‰€æœ‰ Agent è¾“å‡ºå»ºè®®ä¹‹å**
- **ç›®æ ‡**ï¼š**èåˆå½“å‰æ¿€æ´» Agent çš„å»ºè®®ï¼Œç”Ÿæˆæœ€ç»ˆæ“ä½œï¼ˆBuy/Sell/Holdï¼‰**
- **å†³ç­–ç±»å‹**ï¼šç­–ç•¥çº§ã€çŸ­æœŸæ€§
- **æ§åˆ¶åŠ¨ä½œ**ï¼šåŠ æƒèåˆ / å†³ç­–é€‰æ‹© / æŠ•ç¥¨è¡¨å†³ / åŸºäºå†å²å‡†ç¡®ç‡è°ƒæ•´ä¿¡å¿ƒå€¼

ğŸ‘‰ å®ƒæ›´åƒæ˜¯â€œæŠ•èµ„å§”å‘˜ä¼šä¸»å¸­â€ï¼Œå¬å–æ‰€æœ‰åˆ†æå¸ˆçš„æ„è§åæ‹æ¿æœ€ç»ˆå†³ç­–ã€‚

------

### ğŸ” å…¨æµç¨‹ç®€è¦æ—¶åºï¼š

```
å¸‚åœºçŠ¶æ€è¾“å…¥ â†’
Meta-Controllerï¼ˆå†³å®šå‚ä¸çš„Agenté›†åˆï¼‰ â†’
Agentè§’è‰²è¾“å‡ºå»ºè®® â†’
MetaAgentï¼ˆèåˆç­–ç•¥ç”Ÿæˆæœ€ç»ˆæ“ä½œï¼‰ â†’
æ‰§è¡Œäº¤æ˜“ & å›å†™ç»éªŒè®°å¿†
```

------

æˆ‘é©¬ä¸Šåœ¨ä½ çš„ LaTeX æ­£æ–‡ä¸­ï¼Œ**å°†è¿™ä¸€â€œMeta-Controller å‰ç½® + MetaAgent åç½®â€çš„åˆ†å·¥é€»è¾‘åŠ å…¥æ¶æ„ç« èŠ‚çš„è¯´æ˜ä¸­**ï¼Œå¹¶å¼ºè°ƒå®ƒä»¬çš„ RL ç»“åˆæ–¹å¼å’Œæ¶ˆèè¯•éªŒçš„ä»·å€¼ã€‚ä½ ç¨ç­‰ï¼Œæˆ‘æ¥æ›´æ–°ã€‚

ä»¥ä¸‹æ˜¯ä½ åŸå§‹ LaTeX æ­£æ–‡ä¸­ â€œSystem Architecture and Agent Coordinationâ€ éƒ¨åˆ†çš„å¢å¼ºç‰ˆï¼Œå·²å°†ä½ è®¤å¯çš„ Meta-Controllerï¼ˆå‰ç«¯ç»“æ„ç®¡ç†ï¼‰+ MetaAgentï¼ˆåç«¯ç­–ç•¥èåˆï¼‰æœºåˆ¶èå…¥æ¶æ„æµç¨‹ä¸­ï¼Œå¹¶æ˜ç¡®äº†å®ƒä»¬å„è‡ªçš„ RL ç»“åˆæ–¹å¼ä¸èŒè´£åˆ†å·¥ï¼š

------

```latex
\section{System Architecture and Agent Coordination}

We now present our LLM-driven multi-agent system for financial decision-making. The architecture is designed to be modular, adaptive, and grounded in role-based expertise.

\subsection{Framework Overview}

The system comprises five key components:

\begin{itemize}
\item \textbf{Meta-Controller (Structure Manager)}: A high-level controller responsible for managing the system's agent topology. Before each decision round, it evaluates recent market regimes and historical agent performance to determine which agents to activate, suppress, create, merge, or retire. This structural adjustment is partially guided by reinforcement learning and partially by rule-based meta-reasoning (e.g., ReAct + Self-Reflection).

\item \textbf{Specialized Domain Agents}: Each agent corresponds to a financial role (e.g., Technical Analyst, Fundamental Analyst, Sentiment Analyst, Risk Manager), operating on shared market context data. These agents interpret the market from their unique perspective and provide structured outputs.

\item \textbf{Agent Output Format}: Each agent follows a standardized output schema to facilitate coordination:
\begin{verbatim}
Action: [Buy / Hold / Sell]
Confidence: [0.0 ~ 1.0]
Reasoning: [Domain-specific explanation]
\end{verbatim}

\item \textbf{MetaAgent (Policy Fusion Agent)}: After all active domain agents have submitted their suggestions, the MetaAgent performs fusion to derive the final portfolio action. It decides whether to average, vote, or prioritize specific agents based on the context. A reinforcement learning policy governs this fusion process, enabling it to adaptively weigh agent recommendations.

\item \textbf{Central Execution Coordinator (CIO)}: Implements the final action selected by the MetaAgent, and updates the short-term and long-term memory modules accordingly.
\end{itemize}

This pipeline reflects a two-stage decision structure: the \textbf{Meta-Controller} governs team composition (structural evolution), and the \textbf{MetaAgent} governs strategy fusion (policy coordination). This separation enables a more nuanced response to market volatilityâ€”structural adaptation for macro-level shifts, and tactical fusion for micro-level decisions.

All agents process a unified market state composed of historical prices, technical indicators, macroeconomic signals, company fundamentals, and news sentiment. Interaction is asynchronous, and agents are instantiated as local LLM instances with role-specific prompts.

\subsection{Workflow Summary}

Each decision round proceeds as follows:

\begin{enumerate}
\item \textbf{Market Context Ingestion}: System ingests current market state and recent memory logs.
\item \textbf{Meta-Controller Execution}: Decides the agent team composition based on recent performance and market regime.
\item \textbf{Domain Agent Reasoning}: Active agents analyze the shared context and produce structured recommendations.
\item \textbf{MetaAgent Fusion}: Aggregates agent outputs using a learned RL-based fusion policy.
\item \textbf{CIO Execution \& Memory Update}: Final decision is executed, and outcomes are stored into short-term logs and long-term reasoning memory.
\end{enumerate}

This architecture supports both \textbf{vertical adaptation} (better policy fusion over time) and \textbf{horizontal evolution} (agent structure reconfiguration), making it well-suited for the challenges of real-world financial environments.
```

------

å¦‚æœä½ æ‰“ç®—å†™ **æ¶ˆèå®éªŒè®¾è®¡éƒ¨åˆ†ï¼ˆAblation Studyï¼‰**ï¼Œä½ å¯ä»¥åé¢æ¥ç€å†™ç±»ä¼¼ï¼š

```latex
\section{Ablation Studies}

To evaluate the contribution of each self-evolution mechanism, we design ablation experiments that isolate the roles of the Meta-Controller and the MetaAgent. Specifically:

\begin{itemize}
\item \textbf{Without Meta-Controller}: We fix the set of active agents and bypass structural evolution, only allowing the MetaAgent to perform fusion.
\item \textbf{Without MetaAgent (Fixed Fusion)}: We disable RL-based fusion and instead apply static voting or uniform averaging.
\item \textbf{Full System}: Both structural adaptation and policy fusion are governed by learning-based components.
\end{itemize}

We compare the systems across multiple financial metrics, including Sharpe ratio, drawdown resilience, and responsiveness to regime shifts.
```

------

å¦‚éœ€æˆ‘ä¹Ÿä¸€å¹¶è¡¥å…¨æ¶ˆèå®éªŒéƒ¨åˆ†æ­£æ–‡æˆ–ä¿®æ”¹æ•´ç¯‡æ–‡é£ç»Ÿä¸€ã€è¯­è¨€æ‰“ç£¨ï¼Œä¹Ÿå¯ä»¥ç»§ç»­äº¤ç»™æˆ‘ã€‚éœ€è¦å—ï¼Ÿ

# åœ¨æ—©ä¸Šæ¥è¿›è¡Œä¹°å…¥å’Œå–å‡ºæ˜¯å§

å¯¹çš„ï¼Œ**æˆ‘ä»¬é€šå¸¸çº¦å®šåœ¨æ¯å¤©â€œå¼€ç›˜å‰â€å†³å®šä¹°å…¥æˆ–å–å‡ºæ“ä½œï¼Œå¹¶åœ¨â€œå½“å¤©å¼€ç›˜æ—¶â€æ‰§è¡Œè¿™ä¸ªæ“ä½œ**ã€‚è¿™æ ·åšç¬¦åˆä¸¤ä¸ªå…³é”®åŸåˆ™ï¼š

------

### âœ… ä¸ºä»€ä¹ˆé€‰æ‹©æ—©ä¸Šä¹°å…¥/å–å‡ºï¼Ÿ

| åŸå›                    | è§£é‡Š                                                         |
| ---------------------- | ------------------------------------------------------------ |
| ğŸ“‰ **é¿å…æœªæ¥æ•°æ®æ³„éœ²** | å¼ºåŒ–å­¦ä¹ Agentåªèƒ½ä½¿ç”¨ **Tæ—¥ä¹‹å‰çš„æ•°æ®** æ¥é¢„æµ‹T+1æ—¥å¸‚åœºè¡Œä¸ºï¼Œä¸èƒ½å·çœ‹æœªæ¥ã€‚ |
| ğŸ§  **ç¬¦åˆçœŸå®æŠ•èµ„é€»è¾‘** | ç°å®ä¸­ä½ ä¹Ÿæ˜¯åœ¨å‰ä¸€å¤©åˆ†æã€ç¬¬äºŒå¤©ä¸€æ—©æ‰§è¡Œæ“ä½œã€‚               |
| ğŸ’» **ä»£ç å®ç°æ›´æ¸…æ™°**   | åœ¨ `for` å¾ªç¯ä¸­ç”¨ `Tæ—¥æ•°æ® â†’ T+1æ—¥æ‰§è¡Œ`ï¼Œé¡ºåºéå¸¸è‡ªç„¶ï¼Œé¿å…æ··ä¹±ã€‚ |

------

### ğŸ“… ä¸¾ä¸ªä¾‹å­ï¼š

| æ—¥æœŸ         | è¡Œä¸º                                   |
| ------------ | -------------------------------------- |
| Jan 1        | æ”¶ç›˜åï¼ŒAgentæ ¹æ®Jan 1æ•°æ®åšå†³ç­–       |
| Jan 2        | å¼€ç›˜ä»·æ‰§è¡ŒJan 1çš„äº¤æ˜“æŒ‡ä»¤ï¼ˆä¹°å…¥/å–å‡ºï¼‰ |
| Jan 2 æ”¶ç›˜å | å†æ¬¡æ ¹æ®Jan 2æ•°æ®åˆ†æï¼Œä¸ºJan 3åšå‡†å¤‡   |

------

### ğŸ›’ é‚£ä¹ˆæ€ä¹ˆä¹°å…¥å–å‡ºï¼Ÿ

åœ¨å¼ºåŒ–å­¦ä¹ ç¯å¢ƒä¸­æˆ‘ä»¬é€šå¸¸è¿™æ ·å®ç°ï¼š

```python
if action == "Buy" and cash > 0:
    shares = cash // price  # æ•´è‚¡ä¹°å…¥
    cash -= shares * price
elif action == "Sell" and shares > 0:
    cash += shares * price
    shares = 0
```

- `price` é€šå¸¸æ˜¯ **T+1æ—¥çš„å¼€ç›˜ä»·**
- æ¯å¤©åªåšä¸€æ¬¡äº¤æ˜“ï¼ˆé™¤éä½ è®¾è®¡å¤šæ¬¡å†³ç­–ï¼‰
- å¯ä»¥åŠ æ‰‹ç»­è´¹ã€æ»‘ç‚¹ç­‰æ›´çœŸå®çš„å…ƒç´ ï¼ˆåæœŸä¼˜åŒ–ï¼‰

------

éœ€è¦æˆ‘å¸®ä½ å†™ä¸€ä¸ªåŸºç¡€ç‰ˆçš„äº¤æ˜“æ‰§è¡Œå™¨æˆ–å¼ºåŒ–å­¦ä¹ ç¯å¢ƒæ¨¡æ‹Ÿå™¨å—ï¼Ÿä½ åªç®¡å¡è¿›Agentï¼Œæˆ‘æ¥å¸®ä½ å¤„ç†äº¤æ˜“ã€æ”¶ç›Šè®°å½•ã€portfolioæ›´æ–°ã€‚


# æˆ‘æƒ³ä¸€éƒ¨åˆ†éœ€è¦å›ºåŒ–åˆ°csv

éå¸¸æœ‰çœ¼å…‰ï¼ä½ ç°åœ¨æçš„è¿™ä¸ªç‚¹â€”â€”**å°†ä¸€éƒ¨åˆ† Agent çš„è¡¨ç°/çŠ¶æ€å›ºåŒ–åˆ° CSV**ï¼Œæ˜¯æˆ‘ä»¬æ„å»ºã€Œè®°å¿†æœºåˆ¶ + åŠ¨æ€ç»“æ„æ§åˆ¶ã€ç³»ç»Ÿéå¸¸å…³é”®çš„ä¸€æ­¥ã€‚

------
## ğŸ§  ä¸ºä»€ä¹ˆéœ€è¦å›ºåŒ–åˆ° CSVï¼Ÿ

### âœ… ç›®çš„ï¼š

1. **è®°å½•æ¯ä¸ª Agent æ¯æ—¥è¡¨ç°ï¼ˆä¾‹å¦‚ï¼šæ“ä½œå»ºè®® + ä¿¡å¿ƒå€¼ + rewardï¼‰**
2. **é•¿æœŸç§¯ç´¯ Track Recordï¼Œä¾› MetaController è°ƒç”¨ï¼ˆæ¯”å¦‚ï¼šå†»ç»“æœ€è¿‘è¡¨ç°å·®çš„ Agentï¼‰**
3. **æ”¯æŒè®­ç»ƒè®°å¿†æ¨¡å—æˆ– RL æ¨¡å‹çš„ Replay å›æ”¾**

### âœ… å»ºè®®ç»“æ„ï¼ˆCSV æ–‡ä»¶ï¼‰

æˆ‘ä»¬å¯ä»¥ä¿å­˜ä¸ºä¸€ä¸ª `agent_memory.csv` æ–‡ä»¶ï¼Œæ¯å¤©éƒ½è¿½åŠ ä¸€è¡Œè®°å½•ï¼š

| date       | agent_name         | action | confidence | reward | accuracy_rolling | was_selected | market_state_summary      |
| ---------- | ------------------ | ------ | ---------- | ------ | ---------------- | ------------ | ------------------------- |
| 2025-01-01 | TechnicalAnalyst   | buy    | 0.82       | 0.03   | 0.78             | 1            | turbulence:12.4, vix:18.7 |
| 2025-01-01 | FundamentalAnalyst | hold   | 0.61       | 0.01   | 0.85             | 1            | ...                       |
| ...        | ...                | ...    | ...        | ...    | ...              | ...          | ...                       |

### å­—æ®µè¯´æ˜ï¼š

- `date`ï¼šå½“å‰å›åˆæ—¥æœŸ
- `agent_name`ï¼šAgent æ ‡è¯†
- `action`ï¼šbuy / sell / hold
- `confidence`ï¼šAgent è¾“å‡ºçš„ä¿¡å¿ƒå€¼
- `reward`ï¼šè¿™ä¸ª action æœ€ç»ˆå¸¦æ¥çš„æ”¶ç›Šï¼ˆæ¬¡æ—¥æ¶¨è·Œï¼‰
- `accuracy_rolling`ï¼šè¿‡å» N æ—¥å‘½ä¸­ç‡ï¼ˆMetaController ä¼šå‚è€ƒå®ƒï¼‰
- `was_selected`ï¼šè¯¥æ—¥æ˜¯å¦è¢« MetaController æ¿€æ´»ï¼ˆç”¨äºè®­ç»ƒé€‰æ‹©ç­–ç•¥ï¼‰
- `market_state_summary`ï¼šå¯é€‰æ‘˜è¦ï¼Œç”¨äºåæœŸè®­ç»ƒ memory æˆ– MetaController çš„è¾…åŠ©ç‰¹å¾ï¼ˆå¯ä¸º JSON æˆ–å­—ç¬¦ä¸²ï¼‰

------

## ğŸ›  æ€ä¹ˆå®ç°ï¼ˆä½ åªéœ€åšè¿™å‡ æ­¥ï¼‰ï¼š

### âœ… ç¬¬ä¸€æ­¥ï¼šå®šä¹‰ä¸€ä¸ªè®°å½•å‡½æ•°

```python
import csv
from datetime import datetime

def record_agent_memory(path, record):
    file_exists = os.path.isfile(path)
    with open(path, 'a', newline='') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=list(record.keys()))
        if not file_exists:
            writer.writeheader()
        writer.writerow(record)
```

### âœ… ç¬¬äºŒæ­¥ï¼šæ¯ä¸ª Agent æ‰§è¡Œå®Œåè°ƒç”¨

```python
record_agent_memory(
    path='agent_memory.csv',
    record={
        'date': current_date,
        'agent_name': agent.name,
        'action': agent_output['action'],
        'confidence': agent_output['confidence'],
        'reward': agent_reward,
        'accuracy_rolling': compute_accuracy(agent.name),
        'was_selected': True,
        'market_state_summary': summarize_market_state(market_state)
    }
)
```

------

## ğŸ¯ åç»­ç”¨é€”

| ç”¨é€”                              | æ“ä½œ                                                  |
| --------------------------------- | ----------------------------------------------------- |
| MetaController å†³å®šæ¿€æ´»å“ªäº› Agent | æŸ¥çœ‹æ¯ä¸ª Agent çš„ `accuracy_rolling`, `reward` å¹³ç¨³æ€§ |
| å†³ç­–èåˆæ¨¡å—åŠ æƒ                  | åŠ¨æ€ä½¿ç”¨å†å²è¡¨ç°ä½œä¸ºèåˆæƒé‡                          |
| åˆ†æ Agent è´¡çŒ®                   | è¯„ä¼°å“ªäº› Agent åœ¨ä»€ä¹ˆåœºæ™¯ä¸‹æ›´æœ‰ç”¨                     |
| è®­ç»ƒé•¿æœŸè®°å¿†ç½‘ç»œ                  | æŠ½å–çŠ¶æ€ + åŠ¨ä½œ + å¥–åŠ±åºåˆ—è®­ç»ƒ LSTM ç­‰ç»“æ„            |

------

æˆ‘å»ºè®®ä½ ä»**â€œæ¯å¤©è®°å½•æ‰€æœ‰ agent è¾“å‡ºä¸ rewardâ€**å¼€å§‹ï¼Œç­‰æ•°æ®ç§¯ç´¯åˆ°ä¸€å®šé‡ä¹‹åå†å¼•å…¥é•¿æœŸè®°å¿†å»ºæ¨¡æ¨¡å—ã€‚

å¦‚æœä½ è§‰å¾—è¿™ä¸ªæ ¼å¼ OKï¼Œæˆ‘å¯ä»¥å¸®ä½ æŠŠè¿™ä¸ªè®°å½•æœºåˆ¶åŠ åˆ°ä½ ç°æœ‰çš„ `MetaAgent` å’Œæœªæ¥çš„ `AgentOrchestrator` æ¶æ„ä¸­ï¼Œç»„æˆé—­ç¯è®°å¿†ç³»ç»Ÿã€‚è¦ä¸è¦æˆ‘ç°åœ¨å¼€å§‹è¡¥ï¼Ÿ